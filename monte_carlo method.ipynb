{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec8f784a",
   "metadata": {},
   "source": [
    "# MC Method-Episodic_MDP\n",
    "무조건 종료하는 MDP 여야 한다. \n",
    "=> 에피소드가 끝나기 전에 벨류값을 업데이트 하고 싶다면, 종료하지 않는 MDP 사용 => Temporal Difference 사용(추축을 추축한다)\n",
    "모든 에피소드가 끝나고, 리턴값을 알아야 하기 때문에 학습시점에서는 불리, 하지만 불편 추정량(편향x)특징을 가지고 있다는 장점이 있다.\n",
    "분산이 크다. 평균적으로 값들이 멀리 퍼져있다.\n",
    "수십 개의 수백개의 확률적인 값, 변동성이 크다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18af7ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Lib\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31a99d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment \n",
    "class GridWorld():\n",
    "    def __init__(self):\n",
    "        self.x=0\n",
    "        self.y=0\n",
    "        \n",
    "    def step(self,a):\n",
    "        # 액션 지정 4방향\n",
    "        if a == 0:\n",
    "            self.move_left()\n",
    "        elif a==1:\n",
    "            self.move_up()\n",
    "        elif a==2:\n",
    "            self.move_right()\n",
    "        elif a==3:\n",
    "            self.move_down()\n",
    "        \n",
    "        reward = -1\n",
    "        done = self.is_done()\n",
    "        return (self.x, self.y), reward, done\n",
    "    \n",
    "    def move_right(self):\n",
    "        self.y += 1\n",
    "        if self.y >3:\n",
    "            self.y = 3\n",
    "            \n",
    "    def move_left(self):\n",
    "        self.y -= 1\n",
    "        if self.y<0:\n",
    "            self.y = 0\n",
    "            \n",
    "    def move_up(self):\n",
    "        self.x -= 1\n",
    "        if self.x< 0:\n",
    "            self.x = 0\n",
    "            \n",
    "    def move_down(self):\n",
    "        self.x += 1\n",
    "        if self.x>3:\n",
    "            self.x = 3\n",
    "\n",
    "    def is_done(self):\n",
    "        if self.x ==3 and self.y==3:\n",
    "            return True\n",
    "        else :\n",
    "            return False\n",
    "        \n",
    "    def reset(self):\n",
    "        self.x =0\n",
    "        self.y =0\n",
    "        return (self.x,self.y)\n",
    "    \n",
    "    def get_state(self):\n",
    "        return (self.x,self.y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04d86974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent set the actions\n",
    "class Agent(): # 각 class엔 무조건 init 함수가 있어야 한다.\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def select_action(self):\n",
    "        coin = random.random() # cion = 0 ~ 1\n",
    "        \n",
    "        if coin<0.25:\n",
    "            action = 0\n",
    "        elif coin<0.5:\n",
    "            action = 1\n",
    "        elif coin<0.75:\n",
    "            action = 2\n",
    "        else :\n",
    "            action = 3\n",
    "            \n",
    "        return action\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c25d574",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-59.441741571675536, -57.15650193512179, -53.866014087878256, -51.6756589502767]\n",
      "[-56.74172909534625, -54.32315322856434, -49.5517705244433, -44.502529255852885]\n",
      "[-53.823527981941076, -48.93549683689829, -40.35747505119504, -29.152699317874788]\n",
      "[-50.70030622098298, -44.051671189147385, -30.31068825285, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# main function\n",
    "def main():\n",
    "    env = GridWorld()\n",
    "    agent = Agent()\n",
    "    data = [[0,0,0,0],[0,0,0,0],[0,0,0,0],[0,0,0,0]]\n",
    "    gamma = 1.0\n",
    "    alpha = 0.0001 # learning rate: 한꺼번에 얼만큼의 값을 보고 업데이트 할 것인지\n",
    "    \n",
    "    for k in range(50000):\n",
    "        done = False\n",
    "        history = []\n",
    "        \n",
    "        while not done:\n",
    "            action = agent.select_action()\n",
    "            (x,y), reward, done = env.step(action)\n",
    "            history.append((x,y,reward))\n",
    "        env.reset()\n",
    "        \n",
    "        \n",
    "        # Update Table\n",
    "        cum_reward = 0\n",
    "        for transition in history[::-1]: # 뒤에서 부터 결정\n",
    "            x, y, reward = transition\n",
    "            #print(transition)\n",
    "            data[x][y] = data[x][y] + alpha*(cum_reward-data[x][y]) # value update\n",
    "            cum_reward = reward + gamma*cum_reward # return Gt\n",
    "            \n",
    "    for row in data:\n",
    "        print(row)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a610a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
